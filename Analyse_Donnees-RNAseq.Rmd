---
title: "ANALYSE DE DONNEES RNASeq 16S BACTERIEN"
author: "Serigne Fallou Mbacke NGOM"
date: "2023-07-03"
output: html_document
---

# CHARGER ET VOIR LA VERSION DE DADA2 :
```{r}
library("dada2")
packageVersion("dada2")
```


# EXTRAIRE LES DONNEES FASTQ :
```{r}
path <- "C:/BIOINFORMATIQUE/R/Analyse_donnees_RNAseq/MiSeq_SOP-1" 
list.files(path)
```


# RECUPERER LES BRINS SENS (R1) et ANTISENS (R2) :
```{r}
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))  # forward ou sens
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))  # reverse ou antisens

sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)  # assuming filenames have format: SAMPLENAME_XXX.fastq
print(sample.names)
```


# INSPECTER LA QULITE DES READS :
```{r, warning=FALSE}
plotQualityProfile(fnFs[]) # visualisation qualite des reads brins sens ou forward

```
```{r, warning=FALSE}
plotQualityProfile(fnFs[4:6]) # visualisation qualite des reads 4/5/6 brins sens ou forward

```

Nous avons ici la qualite des reads pour les amorces sens. 
*INTERPRETATION: * 
- In gray-scale is a heat map of the frequency of each quality score at each base position;
- The mean quality score at each position is shown by the green line; 
- the quartiles of the quality score distribution by the orange lines;
- The red line shows the scaled proportion of reads that extend to at least that position.

Nous avons constate que la qualite est generalement bonne pour ces reads foward, neanmoins on note une baisse de la qualite au dela de 240nt donc il est recommande de couper les sequences a ce niveau pour les 


```{r, warning=FALSE}
plotQualityProfile(fnRs[1:3])   # visualisation qualite des 3 primiers reads antisens ou reverse

```
*INTERPRETATION: * 
Nous avons constate que pour les reads reverse ou antisens, la qualite est faible (habituel pour les sequenceurs Illimuna). Au dela de 160nt, la qualite ddeviens de plus en plus mauvaise donc il est recommande de supprimer cette partie par coupure sur ces reads.


# FILTRAGE ET COUPURE DES READS :

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160), # coupure des reads, trimming
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) 
head(out)
```
Nous avons cree un dossier "filterd" contenant tous les reads coupe ( a partir de 240 nt pour les fowards et 160 pour les reverse).

```{r, warning=FALSE}
plotQualityProfile(filtFs[4:6])   # visualisation qualite des reads 4/5/6 forward apres coupure

plotQualityProfile(filtRs[1:3])   # visualisation qualite des 3 primiers reads reverse apres coupure

```


# TAUX D'ERREUR :

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)

```
```{r, warning=FALSE}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)

```
- Points are the observed error rates for each consensus quality score. 
- The black line shows the estimated error rates after convergence of the machine-learning algorithm. 
- The red line shows the error rates expected under the nominal definition of the Q-score. 


# INFERER LES ECHANTILLONS AVEC DONNEES FILTREES :

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE) # recuperer les sequences uniques

```
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)

```
```{r}
dadaFs[[1]]

```
```{r}
dadaFs[[3]]
```


# MERGER LES DONNEES :
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
head(mergers[[1]])  # Inspect the merger data.frame from the first sample

```

*PS: Non-overlapping reads are supported, but not recommended, with mergePairs(..., justConcatenate=TRUE).*


# CONSTRUCTION D'UN TABLEAU DE VARIANTS :
We can now construct an amplicon sequence variant table (ASV) table, a higher-resolution version of the OTU table produced by traditional methods

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
table(nchar(getSequences(seqtab)))  # Inspect distribution of sequence lengths

```
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
```{r, warning=FALSE}
sum(seqtab.nochim)/sum(seqtab)
```
The frequency of chimeric sequences varies substantially from dataset to dataset, and depends on on factors including experimental procedures and sample complexity.
when we account for the abundances of those variants we see they account for only about 4% of the merged sequence reads.


# RESUME EVOLUTION ANALYSES:

```{r, warning=FALSE}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```


# ASSIGNATION DES TAXANOMIE :
It is common at this point, especially in 16S/18S/ITS amplicon sequencing, to assign taxonomy to the sequence variants. The DADA2 package provides a native implementation of the naive Bayesian classifier method for this purpose. The assignTaxonomy function takes as input a set of sequences to be classified and a training set of reference sequences with known taxonomy, and outputs taxonomic assignments with at least minBoot bootstrap confidence.
We maintain formatted training fastas for the RDP training set, GreenGenes clustered at 97% identity, and the Silva reference database, and additional trainings fastas suitable for protists and certain specific environments have been contributed. For fungal taxonomy, the General Fasta release files from the UNITE ITS database can be used as is. To follow along, download the silva_nr_v132_train_set.fa file, and place it in the directory with the fastq files
```{r}
taxa1 <- assignTaxonomy(seqtab.nochim, "C:/BIOINFORMATIQUE/R/Analyse_donnees_RNAseq/fichiers_taxanomy/silva_nr_v132_train_set.fa", multithread=TRUE)

```

```{r, warning=FALSE}
taxa.print <- taxa1   # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

```
Les Bacteriodes sont tres representatifs dans nos echantillons.



# Evaluate accuracy:

Evaluating DADA2’s accuracy on the mock community:
```{r, warning=FALSE}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")

mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
*INTERPRETATION:*
This mock community contained 20 bacterial strains. DADA2 identified 20 ASVs all of which exactly match the reference genomes of the expected community members. The residual error rate after the DADA2 pipeline for this sample is 0%.


# ANALYSE AVEC PHYLOSEQ :
The phyloseq R package is a powerful framework for further analysis of microbiome data. We now demonstrate how to straightforwardly import the tables produced by the DADA2 pipeline into phyloseq. We’ll also add the small amount of metadata we have – the samples are named by the gender (G), mouse subject number (X) and the day post-weaning (Y) it was sampled (eg. GXDY).

```{r, warning=FALSE}
library(phyloseq); packageVersion("phyloseq")
```
```{r, warning=FALSE}
library(Biostrings); packageVersion("Biostrings")
```
```{r, warning=FALSE}
library(ggplot2); packageVersion("ggplot2")
```
```{r}
theme_set(theme_bw())
```

We can construct a simple sample data.frame from the information encoded in the filenames. Usually this step would instead involve reading the sample data in from a file.
```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```

We now construct a phyloseq object directly from the dada2 outputs.
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa1))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample  
```

we’ll store the DNA sequences of our ASVs in the refseq slot of the phyloseq object, and then rename our taxa to a short string. That way, the short new taxa names will appear in tables and plots, and we can still recover the DNA sequences corresponding to each ASV as needed with refseq(ps).
```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```

# Visualize alpha-diversity:

```{r, warning=FALSE}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```
```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
```
```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```

DIAGRAMME EN BARRE
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```

